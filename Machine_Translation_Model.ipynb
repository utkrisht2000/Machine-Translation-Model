{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation_Model.ipynb",
      "provenance": [],
      "mount_file_id": "1ojFNk3mST-DymHR-oBUR3AnKRsRj8l7x",
      "authorship_tag": "ABX9TyMxRaICbSIy2Bkn6dFLusDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkrisht2000/Machine-Translation-Model/blob/main/Machine_Translation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wcsczWBG7uL"
      },
      "outputs": [],
      "source": [
        "# Import Dataset\n",
        "\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils.vis_utils import plot_model\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Projects/Machine_Translation_Model/English.txt\"\n",
        "data_path2 = \"/content/drive/MyDrive/Projects/Machine_Translation_Model/Hindi.txt\"\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().strip().split('\\n')\n",
        "with open(data_path2, 'r', encoding='utf-8') as f:\n",
        "  lines2 = f.read().strip().split('\\n')\n",
        "\n",
        "lines = [\" \".join(re.findall(r\"[A-Za-z0-9]+\",line)) for line in lines]\n",
        "lines2 = [re.sub(r\"%s|\\(|\\)|<|>|%|[a-z]|[A-Z]|_\",'',line) for line in lines2]\n",
        "\n",
        "# Grouping lines by response pair\n",
        "pairs = list(zip(lines,lines2))\n",
        "random.shuffle(pairs)\n",
        "print(len(pairs))\n",
        "print(pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08gdCY8y4wEr",
        "outputId": "f9d1b809-4137-4824-aca9-05e5da21a0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "('their least favorite fruit is the mango but your least favorite is the strawberry', 'उनका सबसे पसंदीदा फल आम है, लेकिन आपका सबसे पसंदीदा फल स्ट्रॉबेरी है।')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for line in pairs:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split(\" \"):\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)\n",
        "\n",
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())\n",
        "\n",
        "\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n",
        "\n",
        "print(target_docs[0],input_docs[0],num_decoder_tokens,num_encoder_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYNS68B34wHu",
        "outputId": "8c0efd63-373b-4950-d013-c5c70e0c09f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> उनक ा सबस े पस ं द ी द ा फल आम ह ै , ल े क ि न आपक ा सबस े पस ं द ी द ा फल स ् ट ् र ॉ ब े र ी ह ै । <END> their least favorite fruit is the mango but your least favorite is the strawberry 238 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 256\n",
        "epochs = 44\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# #Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# #Compiling\n",
        "training_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Steps Of RNN\n",
        "plot_model(training_model, to_file='/content/drive/MyDrive/Projects/Next_Word_Prediction/plot.png', show_layer_names=True)\n",
        "\n",
        "#Training\n",
        "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2).history\n",
        "training_model.save('/content/drive/MyDrive/Projects/Machine_Translation_Model/training_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNRT8SLx4wJ8",
        "outputId": "11f2f862-dbb3-4e0d-f4ff-cd588cf19535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "32/32 [==============================] - 70s 2s/step - loss: 2.4272 - accuracy: 0.0420 - val_loss: 2.1799 - val_accuracy: 0.0434\n",
            "Epoch 2/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 2.1678 - accuracy: 0.0440 - val_loss: 2.1780 - val_accuracy: 0.0456\n",
            "Epoch 3/44\n",
            "32/32 [==============================] - 67s 2s/step - loss: 2.1560 - accuracy: 0.0460 - val_loss: 2.1688 - val_accuracy: 0.0462\n",
            "Epoch 4/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 2.1435 - accuracy: 0.0463 - val_loss: 2.1563 - val_accuracy: 0.0464\n",
            "Epoch 5/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 2.1340 - accuracy: 0.0470 - val_loss: 2.1436 - val_accuracy: 0.0466\n",
            "Epoch 6/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 2.1203 - accuracy: 0.0472 - val_loss: 2.1288 - val_accuracy: 0.0479\n",
            "Epoch 7/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 2.0987 - accuracy: 0.0480 - val_loss: 2.1052 - val_accuracy: 0.0480\n",
            "Epoch 8/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 2.0778 - accuracy: 0.0494 - val_loss: 2.0834 - val_accuracy: 0.0512\n",
            "Epoch 9/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 2.0532 - accuracy: 0.0510 - val_loss: 2.0613 - val_accuracy: 0.0527\n",
            "Epoch 10/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 2.0301 - accuracy: 0.0549 - val_loss: 2.0345 - val_accuracy: 0.0547\n",
            "Epoch 11/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 2.0033 - accuracy: 0.0597 - val_loss: 2.0065 - val_accuracy: 0.0612\n",
            "Epoch 12/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.9953 - accuracy: 0.0614 - val_loss: 1.9906 - val_accuracy: 0.0664\n",
            "Epoch 13/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.9617 - accuracy: 0.0694 - val_loss: 1.9647 - val_accuracy: 0.0705\n",
            "Epoch 14/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.9322 - accuracy: 0.0769 - val_loss: 1.9319 - val_accuracy: 0.0785\n",
            "Epoch 15/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.9015 - accuracy: 0.0882 - val_loss: 1.9076 - val_accuracy: 0.0963\n",
            "Epoch 16/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.8716 - accuracy: 0.1023 - val_loss: 1.8763 - val_accuracy: 0.1036\n",
            "Epoch 17/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.8341 - accuracy: 0.1159 - val_loss: 1.8347 - val_accuracy: 0.1175\n",
            "Epoch 18/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.7989 - accuracy: 0.1248 - val_loss: 1.7952 - val_accuracy: 0.1291\n",
            "Epoch 19/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.7592 - accuracy: 0.1379 - val_loss: 1.7543 - val_accuracy: 0.1399\n",
            "Epoch 20/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 1.7129 - accuracy: 0.1491 - val_loss: 1.7108 - val_accuracy: 0.1557\n",
            "Epoch 21/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.6637 - accuracy: 0.1651 - val_loss: 1.6663 - val_accuracy: 0.1737\n",
            "Epoch 22/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.6150 - accuracy: 0.1813 - val_loss: 1.6035 - val_accuracy: 0.1989\n",
            "Epoch 23/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 1.5665 - accuracy: 0.2029 - val_loss: 1.5523 - val_accuracy: 0.2083\n",
            "Epoch 24/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.5027 - accuracy: 0.2251 - val_loss: 1.4905 - val_accuracy: 0.2368\n",
            "Epoch 25/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.4426 - accuracy: 0.2461 - val_loss: 1.4511 - val_accuracy: 0.2408\n",
            "Epoch 26/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 1.3804 - accuracy: 0.2638 - val_loss: 1.3598 - val_accuracy: 0.2742\n",
            "Epoch 27/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 1.3057 - accuracy: 0.2804 - val_loss: 1.2846 - val_accuracy: 0.2879\n",
            "Epoch 28/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.2305 - accuracy: 0.2987 - val_loss: 1.2157 - val_accuracy: 0.3065\n",
            "Epoch 29/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 1.1728 - accuracy: 0.3177 - val_loss: 1.1535 - val_accuracy: 0.3287\n",
            "Epoch 30/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 1.1064 - accuracy: 0.3335 - val_loss: 1.0887 - val_accuracy: 0.3388\n",
            "Epoch 31/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 1.0427 - accuracy: 0.3444 - val_loss: 1.0245 - val_accuracy: 0.3531\n",
            "Epoch 32/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.9845 - accuracy: 0.3567 - val_loss: 0.9697 - val_accuracy: 0.3645\n",
            "Epoch 33/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 0.9308 - accuracy: 0.3676 - val_loss: 0.9152 - val_accuracy: 0.3742\n",
            "Epoch 34/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.8798 - accuracy: 0.3773 - val_loss: 0.8698 - val_accuracy: 0.3827\n",
            "Epoch 35/44\n",
            "32/32 [==============================] - 68s 2s/step - loss: 0.8350 - accuracy: 0.3890 - val_loss: 0.8267 - val_accuracy: 0.3967\n",
            "Epoch 36/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.7937 - accuracy: 0.3998 - val_loss: 0.7947 - val_accuracy: 0.4041\n",
            "Epoch 37/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 0.7574 - accuracy: 0.4075 - val_loss: 0.7639 - val_accuracy: 0.4097\n",
            "Epoch 38/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.7235 - accuracy: 0.4148 - val_loss: 0.7176 - val_accuracy: 0.4212\n",
            "Epoch 39/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.6912 - accuracy: 0.4219 - val_loss: 0.6885 - val_accuracy: 0.4278\n",
            "Epoch 40/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.6634 - accuracy: 0.4280 - val_loss: 0.6607 - val_accuracy: 0.4338\n",
            "Epoch 41/44\n",
            "32/32 [==============================] - 64s 2s/step - loss: 0.6375 - accuracy: 0.4330 - val_loss: 0.6376 - val_accuracy: 0.4372\n",
            "Epoch 42/44\n",
            "32/32 [==============================] - 66s 2s/step - loss: 0.6159 - accuracy: 0.4361 - val_loss: 0.6167 - val_accuracy: 0.4389\n",
            "Epoch 43/44\n",
            "32/32 [==============================] - 65s 2s/step - loss: 0.5951 - accuracy: 0.4389 - val_loss: 0.6019 - val_accuracy: 0.4409\n",
            "Epoch 44/44\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.5763 - accuracy: 0.4417 - val_loss: 0.5761 - val_accuracy: 0.4464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.savefig('/content/drive/MyDrive/Projects/Machine_Translation_Model/accuracy.png')\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'o', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.savefig('/content/drive/MyDrive/Projects/Machine_Translation_Model/loss.png')\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWB7GTU8HUda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cc45e730-ec71-4cb8-bb17-215cfac55f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e15b8db2df1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "\n",
        "training_model = load_model('/content/drive/MyDrive/Projects/Machine_Translation_Model/training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    decoded_sentence = ''\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "      output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "      decoded_sentence += \" \" + sampled_token\n",
        "      if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "        stop_condition = True\n",
        "      target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "      target_seq[0, 0, sampled_token_index] = 1.\n",
        "      states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "Qmf05YtNHUjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Translator Class\n",
        "\n",
        "class Translator:\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "  \n",
        "  #Method to start the translator\n",
        "  def start(self):\n",
        "    user_response = input(\"Give in an English sentence. :) \\n\")\n",
        "    self.translate(user_response)\n",
        "  \n",
        "  #Method to handle the conversation\n",
        "  def translate(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "\n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "  \n",
        "  #Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "BgUujEskHUlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate English To Hindi\n",
        "\n",
        "translator.start()"
      ],
      "metadata": {
        "id": "P-ilxrxsHUoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}